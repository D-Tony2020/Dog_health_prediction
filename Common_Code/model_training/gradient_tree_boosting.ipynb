{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import joblib\n",
    "from functools import reduce\n",
    "import xgboost as xgb\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "\n",
    "from sklearn.model_selection import train_test_split, StratifiedShuffleSplit, StratifiedKFold\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import roc_auc_score, classification_report\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "# from skmultilearn.model_selection import MultiLabelStratifiedKFold\n",
    "from iterstrat.ml_stratifiers import MultilabelStratifiedKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_breed = pd.read_pickle('../features/breed.pkl')\n",
    "feat_breed_v2 = pd.read_pickle('../features/breed_v2.pkl')\n",
    "\n",
    "feat_breed_top50 = pd.read_pickle('../features/breed_top50.pkl')\n",
    "feat_breed_top50_v2 = pd.read_pickle('../features/breed_top50_v2.pkl')\n",
    "\n",
    "feat_breed_group = pd.read_pickle('../features/breed_group.pkl')\n",
    "feat_sub_breed = pd.read_pickle('../features/sub_breed.pkl')\n",
    "feat_breed_type = pd.read_pickle('../features/breed_type.pkl')\n",
    "\n",
    "feat_breed_pure_or_mix = pd.read_pickle('../features/breed_pure_or_mix.pkl')\n",
    "\n",
    "feat_age = pd.read_csv('../features/age_with_id.csv')\n",
    "feat_sex = pd.read_csv('../features/one_hot_encoded_sex_with_id.csv')\n",
    "\n",
    "# Climate\n",
    "feat_HotWheater = pd.read_csv('../features/HotMonths_with_dog_id.csv')\n",
    "feat_residence = pd.read_csv('../features/Residence_with_dog_id.csv')\n",
    "\n",
    "# Physical Activity\n",
    "feat_pa_total_hours = pd.read_csv('../features/PhysicalActivity_total_hours.csv')\n",
    "feat_pa_surface = pd.read_csv('../features/PhysicalActivity_surface.csv')\n",
    "\n",
    "# Owner Demographics\n",
    "feat_od_income = pd.read_csv('../features/od_income.csv')\n",
    "\n",
    "feat_disease_input = pd.read_csv('../features/one_hot_encoded_disease_input.csv')\n",
    "feat_disease_output_binary = pd.read_csv('../features/disease_output_binary.csv')\n",
    "feat_disease_output = pd.read_csv('../features/disease_output.csv')\n",
    "\n",
    "#Diet\n",
    "feat_diet = pd.read_pickle('../features/diet_merged.pkl')\n",
    "\n",
    "features_list = [\n",
    "    #feat_breed,\n",
    "    #feat_breed_v2,\n",
    "    #feat_breed_top50,\n",
    "    feat_breed_top50_v2,\n",
    "    feat_breed_group,\n",
    "    feat_sub_breed,\n",
    "    feat_breed_type,\n",
    "    feat_breed_pure_or_mix,\n",
    "    feat_age,\n",
    "    feat_sex,\n",
    "    feat_HotWheater,\n",
    "    feat_residence,\n",
    "    feat_pa_total_hours,\n",
    "    feat_pa_surface,\n",
    "    feat_od_income,\n",
    "    feat_diet\n",
    "    #feat_disease_input,\n",
    "    #feat_disease_output_binary,\n",
    "    #feat_disease_output\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp1 = [feat_breed_group]\n",
    "exp2 = [feat_breed_top50_v2]\n",
    "exp3 = [feat_age]\n",
    "exp4 = [feat_sex,feat_breed_type]\n",
    "exp5 = [feat_sub_breed]\n",
    "exp6 = [feat_breed_pure_or_mix]\n",
    "exp7 = [feat_breed_top50_v2,feat_breed_group]\n",
    "exp8 = [feat_breed_top50_v2,feat_breed_group,feat_age,feat_sex]\n",
    "exp9 = [feat_breed_top50_v2,feat_breed_group,feat_age,feat_sex,feat_pa_surface,feat_pa_total_hours]\n",
    "exp10 = [feat_breed_top50_v2,feat_breed_group,feat_age,feat_sex,feat_od_income,feat_HotWheater,feat_residence]\n",
    "exp11 = [feat_breed_top50_v2,feat_breed_group,feat_age,feat_sex,feat_od_income]\n",
    "exp12 = [feat_breed_top50_v2,feat_breed_group,feat_age,feat_sex,feat_od_income,feat_HotWheater,feat_residence,feat_pa_surface,feat_pa_total_hours]\n",
    "exp13 = [feat_breed_top50_v2,feat_breed_group,feat_HotWheater,feat_residence,feat_pa_surface,feat_pa_total_hours]\n",
    "exp14 = [feat_breed_top50_v2,feat_breed_group,feat_HotWheater,feat_residence,feat_pa_surface,feat_pa_total_hours,feat_age,feat_sex,feat_diet]\n",
    "exp15 = [feat_breed_top50_v2,feat_breed_group,feat_HotWheater,feat_residence,feat_pa_surface,feat_pa_total_hours,feat_age,feat_sex,feat_diet]\n",
    "exp16 = [feat_breed_top50_v2,feat_breed_group,feat_HotWheater,feat_residence,feat_pa_surface,feat_pa_total_hours,feat_age,feat_sex,feat_breed_pure_or_mix,feat_breed_type,feat_sub_breed,feat_diet]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiments = {\n",
    "    'exp1': exp1,\n",
    "    'exp2': exp2,\n",
    "    'exp3': exp3,\n",
    "    'exp4': exp4,\n",
    "    'exp5': exp5,\n",
    "    'exp6': exp6,\n",
    "    'exp7': exp7,\n",
    "    'exp8': exp8,\n",
    "    'exp9': exp9,\n",
    "    'exp10': exp10,\n",
    "    'exp11': exp11,\n",
    "    'exp12': exp12,\n",
    "    'exp13': exp13,\n",
    "    'exp15': exp15,\n",
    "    'exp16': exp16\n",
    "}\n",
    "results = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "exp1: Average AUC = 0.5626\n",
      "exp2: Average AUC = 0.5776\n",
      "exp3: Average AUC = 0.6665\n",
      "exp4: Average AUC = 0.5591\n",
      "exp5: Average AUC = 0.5668\n",
      "exp6: Average AUC = 0.5227\n",
      "exp7: Average AUC = 0.5823\n",
      "exp8: Average AUC = 0.6968\n",
      "exp9: Average AUC = 0.6960\n",
      "exp10: Average AUC = 0.6932\n",
      "exp11: Average AUC = 0.6927\n",
      "exp12: Average AUC = 0.6944\n",
      "exp13: Average AUC = 0.6009\n",
      "exp15: Average AUC = 0.7012\n"
     ]
    }
   ],
   "source": [
    "for exp_name, exp_features in experiments.items():\n",
    "    # List of DataFrames to be merged\n",
    "    list_input_features = features_list  # Add more DataFrames as needed\n",
    "\n",
    "    # Merge DataFrames iteratively using reduce\n",
    "    input_features = reduce(lambda left, right: pd.merge(left, right, on='dog_id'), exp_features)\n",
    "\n",
    "    # Merge with disease output feature\n",
    "    data = pd.merge(input_features, feat_disease_output_binary, on='dog_id')\n",
    "\n",
    "    # Assuming 'data' is your DataFrame\n",
    "    rows_with_nan = data[data.isna().any(axis=1)]\n",
    "    columns_with_nan = data.columns[data.isna().any()].tolist()\n",
    "    # Display the rows with NaN values\n",
    "    rows_with_nan[columns_with_nan]\n",
    "    # Separate features and labels\n",
    "    X = data.drop(['dog_id'] + ['hs_health_conditions_' + condition for condition in [\n",
    "        'eye', 'ear', 'oral', 'skin', 'cardiac', 'respiratory', 'gastrointestinal',\n",
    "        'liver', 'kidney', 'reproductive', 'orthopedic', 'neurological', 'endocrine',\n",
    "        'hematologic', 'immune', 'infectious_disease', 'toxin_consumption', 'trauma', 'cancer'\n",
    "    ]], axis=1)\n",
    "\n",
    "    y_columns = ['hs_health_conditions_' + condition for condition in [\n",
    "        'eye', 'ear', 'oral', 'skin', 'cardiac', 'respiratory', 'gastrointestinal',\n",
    "        'liver', 'kidney', 'reproductive', 'orthopedic', 'neurological', 'endocrine',\n",
    "        'hematologic', 'immune', 'infectious_disease', 'toxin_consumption', 'trauma', 'cancer'\n",
    "    ]]\n",
    "    y = data[y_columns]\n",
    "\n",
    "    # Convert y to a binary format\n",
    "    y_binary = (y == 1)\n",
    "\n",
    "    # Initialize the Naive Bayes model\n",
    "    model = GradientBoostingClassifier(n_estimators=100, learning_rate=0.1, max_depth=3, random_state=42)\n",
    "\n",
    "    # Wrap the model with OneVsRestClassifier\n",
    "    ovr_classifier = OneVsRestClassifier(model)\n",
    "\n",
    "    # Initialize MultilabelStratifiedKFold\n",
    "    n_splits = 5  # You can adjust the number of splits as needed\n",
    "    ml_stratified_kfold = MultilabelStratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "    auc_scores_per_fold = []\n",
    "    # Lists to store AUC scores and sample counts\n",
    "    auc_scores_per_condition = {condition: [] for condition in y_columns}\n",
    "    sample_counts_per_condition = {condition: [] for condition in y_columns}\n",
    "\n",
    "    # Iterate through the splits\n",
    "    for fold, (train_index, val_index) in enumerate(ml_stratified_kfold.split(X, y_binary)):\n",
    "        X_train, X_val = X.iloc[train_index], X.iloc[val_index]\n",
    "        y_train, y_val = y_binary.iloc[train_index], y_binary.iloc[val_index]\n",
    "\n",
    "        # Train the model\n",
    "        ovr_classifier.fit(X_train, y_train)\n",
    "\n",
    "        # Make predictions on the validation set\n",
    "        y_pred_proba = ovr_classifier.predict_proba(X_val)\n",
    "\n",
    "        # Calculate the AUC score for each disease\n",
    "        auc_scores = [roc_auc_score(y_val[column], y_pred_proba[:, i]) for i, column in enumerate(y_val.columns)]\n",
    "\n",
    "        auc_scores_per_fold.append(np.mean(auc_scores))\n",
    "        # for i, condition in enumerate(y_columns):\n",
    "        #     sample_count = y_val[condition].sum()  # Count of positive samples for the condition\n",
    "        #     sample_counts_per_condition[condition].append(sample_count)\n",
    "\n",
    "        # # print(f\"\\nFold {fold+1} AUC Scores for Diseases:\")\n",
    "        # for i, auc_score in enumerate(auc_scores, start=1):\n",
    "        #     print(f\"{y_val.columns[i-1]}: {auc_score}\")\n",
    "        #     auc_scores_per_condition[y_val.columns[i-1]].append(auc_score)\n",
    "    # average auc score\n",
    "    average_auc_score = np.mean(auc_scores_per_fold)\n",
    "    results[exp_name] = average_auc_score\n",
    "\n",
    "# print for each exp\n",
    "for exp_name, auc_score in results.items():\n",
    "    print(f\"{exp_name}: Average AUC = {auc_score:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate average AUC per condition\n",
    "average_auc_per_condition = {\n",
    "    condition: sum(auc_scores) / len(auc_scores) for condition, auc_scores in auc_scores_per_condition.items()\n",
    "}\n",
    "# Calculate overall average AUC weighted by the number of samples\n",
    "overall_average_auc_sum = 0\n",
    "for auc_scores, sample_counts in zip(auc_scores_per_condition.values(), sample_counts_per_condition.values()):\n",
    "    weighted_sum = sum(auc * sample_count for auc, sample_count in zip(auc_scores, sample_counts))\n",
    "    overall_average_auc_sum += weighted_sum / sum(sample_counts)\n",
    "\n",
    "overall_average_auc = overall_average_auc_sum / len(auc_scores_per_condition)  # divide by the number of conditions\n",
    "print('overall_average_auc',overall_average_auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Average AUC-score per condition\n",
    "print(\"\\n Average AUC Score per condition:\")\n",
    "for condition, avg_auc in average_auc_per_condition.items():\n",
    "    print(f\"{condition}: {avg_auc}\")\n",
    "\n",
    "# Get average AUC values as a list\n",
    "average_auc_list = list(average_auc_per_condition.values())\n",
    "\n",
    "# Calculate standard deviation of average AUC values\n",
    "overall_auc_std = np.std(average_auc_list)\n",
    "\n",
    "# Print average AUC scores\n",
    "print(\"\\nWeighted Average AUC Score:\")\n",
    "#print(f\"Overall: {overall_average_auc}\")\n",
    "print(f\"{overall_average_auc * 100:.2f}% Â± {overall_auc_std * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save Model as .joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../models/gradient_tree_boosting_with_breedtop50.joblib']"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_filepath = '../models/gradient_tree_boosting_with_breedtop50.joblib'\n",
    "joblib.dump(ovr_classifier, model_filepath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_model_filepath = '../models/gradient_tree_boosting_with_breedtop50.joblib'\n",
    "loaded_ovr_classifier = joblib.load(loaded_model_filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming X_val is your validation set DataFrame\n",
    "# Select a random row (Datapoint) from X_val\n",
    "random_index = np.random.choice(X_val.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Show input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "breeds_American Pitbull Terrier              0\n",
       "breeds_American Staffordshire Terrier        0\n",
       "breeds_Australian Cattle Dog                 0\n",
       "breeds_Australian Shepherd                   0\n",
       "breeds_Basset Hound                          0\n",
       "                                         ...  \n",
       "grass_dirt                                True\n",
       "gravel                                   False\n",
       "sand                                     False\n",
       "astroturf                                False\n",
       "od_annual_income_range_usd                 5.0\n",
       "Name: 8858, Length: 125, dtype: object"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_data_point = X_val.loc[random_index]\n",
    "random_data_point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.7784629e-02, 2.9939476e-02, 4.2124249e-02, 1.3108933e-01,\n",
       "        1.1365089e-03, 2.4033024e-03, 7.0786998e-02, 1.1281752e-03,\n",
       "        1.6732413e-02, 4.4480357e-03, 2.5812009e-02, 1.4144853e-03,\n",
       "        6.3175685e-04, 8.8583899e-04, 2.8188192e-04, 3.5820755e-01,\n",
       "        5.5941883e-02, 1.7371356e-01, 6.2181922e-03]], dtype=float32)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reshape the data point to a 2D array\n",
    "random_data_point_reshaped = random_data_point.values.reshape(1, -1)\n",
    "\n",
    "# Make predictions on the reshaped data point using the loaded model\n",
    "new_data_predictions_proba = loaded_ovr_classifier.predict_proba(random_data_point_reshaped)\n",
    "new_data_predictions_proba"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hh",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
